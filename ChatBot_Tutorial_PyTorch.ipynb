{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> I work through the chatbot tutorial on PyTorch. The chatbot is trained using the  Cornell Movie Dialogs Dataset using a seq2seq model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from __future__ import absolute_import, division, print_function, unicode_literals\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch import optim\n",
    "from torch.jit import script, trace\n",
    "import torch.nn.functional as F\n",
    "import csv\n",
    "import random\n",
    "import re\n",
    "import os\n",
    "import unicodedata\n",
    "import codecs\n",
    "from io import open\n",
    "import itertools\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "b'L1045 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ They do not!\\n'\n",
      "b'L1044 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ They do to!\\n'\n",
      "b'L985 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I hope so.\\n'\n",
      "b'L984 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ She okay?\\n'\n",
      "b\"L925 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Let's go.\\n\"\n",
      "b'L924 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ Wow\\n'\n",
      "b\"L872 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Okay -- you're gonna need to learn how to lie.\\n\"\n",
      "b'L871 +++$+++ u2 +++$+++ m0 +++$+++ CAMERON +++$+++ No\\n'\n",
      "b'L870 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ I\\'m kidding.  You know how sometimes you just become this \"persona\"?  And you don\\'t know how to quit?\\n'\n",
      "b'L869 +++$+++ u0 +++$+++ m0 +++$+++ BIANCA +++$+++ Like my fear of wearing pastels?\\n'\n"
     ]
    }
   ],
   "source": [
    "# Let's read in some of the data\n",
    "corpus_name = 'cornell movie-dialogs corpus'\n",
    "\n",
    "def printlines(file, n = 10):\n",
    "    with open(file, 'rb') as f:\n",
    "        lines  = f.readlines()\n",
    "    for line in lines[:n]:\n",
    "        print(line)\n",
    "\n",
    "printlines(os.path.join(corpus_name, 'movie_lines.txt'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h4> We need to take this data and extract \"sentence pairs\" that form the basis on which we can train our generative chatbot model.     \n",
    "\n",
    "<h4> Because of the way the data is formatted -- first we need to extract the metadata containing the conversation ids and then group conversations into pairs which can be used for training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def loadlines(filename, fields):\n",
    "    lines = {}\n",
    "    with open(filename, 'r', encoding = 'iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(' +++$+++ ')\n",
    "            lineObj  = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                lineObj[field] = values[i]\n",
    "            lines[lineObj['lineID']] = lineObj\n",
    "\n",
    "    return lines\n",
    "\n",
    "def loadConversations(filename, lines, fields):\n",
    "    conversations = []\n",
    "    with open(filename, 'r', encoding = 'iso-8859-1') as f:\n",
    "        for line in f:\n",
    "            values = line.split(\" +++$+++ \")\n",
    "            # Extract fields\n",
    "            convObj = {}\n",
    "            for i, field in enumerate(fields):\n",
    "                convObj[field] = values[i]\n",
    "            # Convert string to list (convObj[\"utteranceIDs\"] == \"['L598485', 'L598486', ...]\")\n",
    "            lineIds = eval(convObj[\"utteranceIDs\"])\n",
    "            # Reassemble lines\n",
    "            convObj[\"lines\"] = []\n",
    "            for lineId in lineIds:\n",
    "                convObj[\"lines\"].append(lines[lineId])\n",
    "            conversations.append(convObj)\n",
    "    return conversations\n",
    "    \n",
    "\n",
    "def get_sentence_pairs(conversations):\n",
    "    qa_pairs = []\n",
    "    for conversation in conversations:\n",
    "        # Iterate over all the lines of the conversation\n",
    "        for i in range(len(conversation[\"lines\"]) - 1):  # We ignore the last line (no answer for it)\n",
    "            inputLine = conversation[\"lines\"][i][\"text\"].strip()\n",
    "            targetLine = conversation[\"lines\"][i+1][\"text\"].strip()\n",
    "            # Filter wrong samples (if one of the lists is empty)\n",
    "            if inputLine and targetLine:\n",
    "                qa_pairs.append([inputLine, targetLine])\n",
    "    return qa_pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Processing corpus...\n",
      "\n",
      "Loading conversations...\n"
     ]
    }
   ],
   "source": [
    "new_path = os.path.join(corpus_name, \"formatted_movie_lines.txt\")\n",
    "\n",
    "delimiter = '\\t'\n",
    "delimiter = str(codecs.decode(delimiter, \"unicode_escape\"))\n",
    "\n",
    "lines = {}\n",
    "conversations = []\n",
    "MOVIE_LINES_FIELDS = [\"lineID\", \"characterID\", \"movieID\", \"character\", \"text\"]\n",
    "MOVIE_CONVERSATIONS_FIELDS = [\"character1ID\", \"character2ID\", \"movieID\", \"utteranceIDs\"]\n",
    "\n",
    "print(\"\\nProcessing corpus...\")\n",
    "lines = loadlines(os.path.join(corpus_name, \"movie_lines.txt\"), MOVIE_LINES_FIELDS)\n",
    "print(\"\\nLoading conversations...\")\n",
    "conversations = loadConversations(os.path.join(corpus_name, \"movie_conversations.txt\"),\n",
    "                                  lines, MOVIE_CONVERSATIONS_FIELDS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'character1ID': 'u0',\n",
       "  'character2ID': 'u2',\n",
       "  'movieID': 'm0',\n",
       "  'utteranceIDs': \"['L194', 'L195', 'L196', 'L197']\\n\",\n",
       "  'lines': [{'lineID': 'L194',\n",
       "    'characterID': 'u0',\n",
       "    'movieID': 'm0',\n",
       "    'character': 'BIANCA',\n",
       "    'text': 'Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\n'},\n",
       "   {'lineID': 'L195',\n",
       "    'characterID': 'u2',\n",
       "    'movieID': 'm0',\n",
       "    'character': 'CAMERON',\n",
       "    'text': \"Well, I thought we'd start with pronunciation, if that's okay with you.\\n\"},\n",
       "   {'lineID': 'L196',\n",
       "    'characterID': 'u0',\n",
       "    'movieID': 'm0',\n",
       "    'character': 'BIANCA',\n",
       "    'text': 'Not the hacking and gagging and spitting part.  Please.\\n'},\n",
       "   {'lineID': 'L197',\n",
       "    'characterID': 'u2',\n",
       "    'movieID': 'm0',\n",
       "    'character': 'CAMERON',\n",
       "    'text': \"Okay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"}]}]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conversations[:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Writing conversation pairs to new file\n",
      "\n",
      "Sample lines from file:\n",
      "b\"Can we make this quick?  Roxanne Korrine and Andrew Barrett are having an incredibly horrendous public break- up on the quad.  Again.\\tWell, I thought we'd start with pronunciation, if that's okay with you.\\n\"\n",
      "b\"Well, I thought we'd start with pronunciation, if that's okay with you.\\tNot the hacking and gagging and spitting part.  Please.\\n\"\n",
      "b\"Not the hacking and gagging and spitting part.  Please.\\tOkay... then how 'bout we try out some French cuisine.  Saturday?  Night?\\n\"\n",
      "b\"You're asking me out.  That's so cute. What's your name again?\\tForget it.\\n\"\n",
      "b\"No, no, it's my fault -- we didn't have a proper introduction ---\\tCameron.\\n\"\n",
      "b\"Cameron.\\tThe thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\n\"\n",
      "b\"The thing is, Cameron -- I'm at the mercy of a particularly hideous breed of loser.  My sister.  I can't date until she does.\\tSeems like she could get a date easy enough...\\n\"\n",
      "b'Why?\\tUnsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\n'\n",
      "b\"Unsolved mystery.  She used to be really popular when she started high school, then it was just like she got sick of it or something.\\tThat's a shame.\\n\"\n",
      "b'Gosh, if only we could find Kat a boyfriend...\\tLet me see what I can do.\\n'\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n Writing conversation pairs to new file\")\n",
    "with open(new_path, 'w', encoding = 'utf-8') as outfile:\n",
    "    writer = csv.writer(outfile, delimiter=delimiter, lineterminator = '\\n')\n",
    "    for pair in get_sentence_pairs(conversations):\n",
    "        writer.writerow(pair)\n",
    "\n",
    "print(\"\\nSample lines from file:\")\n",
    "printlines(new_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now we need to assemble the sentence pairs into something machine readable -- the following class converts words to indexes and vice versa and also trims infrequent words to speed up training. To do this, it also keeps a count of how many times a word appears in the vocabulary.\n",
    "    \n",
    "<h3> Finally, we also have a MAX_LENGTH to filter out sentences > MAX_LENGTH words. \n",
    "    \n",
    "<h3> All of this boilerplate preprocessing can be used in other NLP seq-to-seq models, so it is useful to assemble this as a class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "PAD_token = 0 # pad short sentences\n",
    "SOS_token = 1 # sentence start token\n",
    "EOS_token = 2 # sentence end token\n",
    "\n",
    "class Voc:\n",
    "    def __init__(self, name):\n",
    "        self.name = name\n",
    "        self.trimmed = False\n",
    "        self.word2index  = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.word2count = {}\n",
    "        self.num_words = 3 \n",
    "    \n",
    "    def addSentences(self, sentence):\n",
    "        for word in sentence.split(' '):\n",
    "            self.addWord(word)\n",
    "    \n",
    "    def addWord(self, word):\n",
    "        if word not in self.word2index:\n",
    "            self.word2index[word] = self.num_words\n",
    "            self.word2count[word] = 1\n",
    "            self.index2word[self.num_words] = word\n",
    "            self.num_words +=1\n",
    "        else:\n",
    "            self.word2count[word] += 1 # if word is seen before, update count by 1\n",
    "    \n",
    "    # remove words below count threshold\n",
    "    def trim(self, min_count):\n",
    "        if self.trimmed():\n",
    "            return\n",
    "        self.trimmed =True\n",
    "        \n",
    "        keep_words = []\n",
    "        \n",
    "        for k, v in self.word2count.items():\n",
    "            if v>=min_count:\n",
    "                keep_words.append(k)\n",
    "        \n",
    "        self.word2index = {}\n",
    "        self.word2count = {}\n",
    "        self.index2word = {PAD_token: \"PAD\", SOS_token: \"SOS\", EOS_token: \"EOS\"}\n",
    "        self.num_words = 3\n",
    "        \n",
    "        for word in keep_words:\n",
    "            self.addWord(word)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_LENGTH = 10\n",
    "\n",
    "def unicode_to_ascii(s):\n",
    "    return ''.join(c for c in unicodedata.normalize('NFD', s) if unicodedata.category(c) != 'Mn')\n",
    "\n",
    "def normalizeString(s):\n",
    "    s = unicode_to_ascii(s.lower().strip())\n",
    "    s  = re.sub(r\"([.!?])\", r\" \\1\", s)\n",
    "    s = re.sub(r\"[^a-zA-Z.!?]+\", r\" \", s)\n",
    "    s = re.sub(r\"\\s+\", r\" \", s).strip()\n",
    "    return s\n",
    "\n",
    "def readVocs(datafile, corpus_name):\n",
    "    print(\"Reading Lines ...\")\n",
    "    \n",
    "    lines = open(datafile, encoding = 'utf-8').\\\n",
    "        read().strip().split('\\n')\n",
    "    \n",
    "    pairs = [[normalizeString(s) for s in l.split('\\t')] for l in lines]\n",
    "    voc = Voc(corpus_name)\n",
    "    return voc, pairs\n",
    "\n",
    "# return only both sentences in the pair are less than MAX_LENGTH\n",
    "def filter_helper(p):\n",
    "    return len(p[0].split(' ')) < MAX_LENGTH and len(p[1].split(' ')) < MAX_LENGTH\n",
    "\n",
    "def filterPairs(pairs):\n",
    "    return [pair for pair in pairs if filter_helper(pair)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Start preparing training data...\n",
      "Reading Lines ...\n",
      "Read 221282 sentence pairs\n",
      "Trimmed to 64271 sentence pairs\n",
      "Counting Words...\n",
      "Counted Words: 18008\n"
     ]
    }
   ],
   "source": [
    "def loadPrepareData(corpus_name, datafile, save_dir):\n",
    "    print(\"Start preparing training data...\")\n",
    "    \n",
    "    voc, pairs = readVocs(datafile, corpus_name)\n",
    "    print(\"Read {!s} sentence pairs\".format(len(pairs)))\n",
    "    pairs = filterPairs(pairs)\n",
    "    print(\"Trimmed to {!s} sentence pairs\".format(len(pairs)))\n",
    "    \n",
    "    print(\"Counting Words...\")\n",
    "    for pair in pairs:\n",
    "        voc.addSentences(pair[0])\n",
    "        voc.addSentences(pair[1])\n",
    "    print(\"Counted Words:\", voc.num_words)\n",
    "    return voc, pairs\n",
    "\n",
    "save_dir = os.path.join(\"data\", \"save\")\n",
    "voc, pairs = loadPrepareData(corpus_name, new_path, save_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> To speed up training, we can also trim any sentences containing rare words. Skipping this for now, since the training dataset isn't too large after trimming large sentences."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "metadata": {},
   "outputs": [],
   "source": [
    "def indexesfromSentence(voc, sentence):\n",
    "    return [voc.word2index[word] for word in sentence.split(' ')] + [EOS_token]\n",
    "\n",
    "# Note that this function below impicitly does a transpose -- putput becomes [MAX_LENGTh, Batch_size]\n",
    "def zeroPadding(l, fillvalue = PAD_token):\n",
    "    return list(itertools.zip_longest(*l, fillvalue = fillvalue))\n",
    "\n",
    "# creates an input tensor\n",
    "def inputVar(l, voc):\n",
    "    indexes_batch = [indexesfromSentence(voc, sentence) for sentence in l]\n",
    "    # indexes_batch has shape == [batch_size, sentence_length]\n",
    "    lengths = torch.tensor([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    # pad_var has shape [MAX_length, batch_size] -- the transpose is implicitly done by zeroPadding. \n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, lengths\n",
    "\n",
    "\n",
    "def binaryMatrix(l, value = PAD_token):\n",
    "    m = []\n",
    "    for i, seq in enumerate(l):\n",
    "        m.append([])\n",
    "        for token in seq:\n",
    "            if token == PAD_token:\n",
    "                m[i].append(0)\n",
    "            else:\n",
    "                m[i].append(1)\n",
    "    return m\n",
    "\n",
    "# this returns padded targeet sequence tensor, with a padding mask and a max target length\n",
    "def OutputVar(l, voc):\n",
    "    indexes_batch = [indexesfromSentence(voc, sentence) for sentence in l]\n",
    "    max_target_len = max([len(indexes) for indexes in indexes_batch])\n",
    "    padList = zeroPadding(indexes_batch)\n",
    "    mask = binaryMatrix(padList)\n",
    "    mask = torch.ByteTensor(mask) # conver to tensor so can run tensor operations on mask.\n",
    "    padVar = torch.LongTensor(padList)\n",
    "    return padVar, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the Training Batches\n",
    "def batch2TrainingData(voc, pair_batch):\n",
    "    pair_batch.sort(key = lambda x: len(x[0].split(' ')), reverse = True)\n",
    "    input_batch, output_batch = [], []\n",
    "    for pair in pair_batch:\n",
    "        input_batch.append(pair[0])\n",
    "        output_batch.append(pair[0])\n",
    "    inp, lengths = inputVar(input_batch, voc)\n",
    "    output, mask, max_target_len = OutputVar(output_batch, voc)\n",
    "    return inp, lengths, output, mask, max_target_len"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "input_variable: tensor([[   52,    79,   351,   654,    55,  7199,     9, 10131],\n",
      "        [  120,    39,  1214,   343,   251,    23,  1504,     4],\n",
      "        [   79,   580,     4,    79,   802,     6,     6,     2],\n",
      "        [    6,   424,  2002,   304,     4,     2,     2,     0],\n",
      "        [   73,   293,  8817,     4,     2,     0,     0,     0],\n",
      "        [ 2748,   103,     4,     2,     0,     0,     0,     0],\n",
      "        [    6,     9,     2,     0,     0,     0,     0,     0],\n",
      "        [ 1956,  3067,     0,     0,     0,     0,     0,     0],\n",
      "        [    6,     4,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,     2,     0,     0,     0,     0,     0,     0]])\n",
      "lengths: tensor([10, 10,  7,  6,  5,  4,  4,  3])\n",
      "target_variable: tensor([[   52,    79,   351,   654,    55,  7199,     9, 10131],\n",
      "        [  120,    39,  1214,   343,   251,    23,  1504,     4],\n",
      "        [   79,   580,     4,    79,   802,     6,     6,     2],\n",
      "        [    6,   424,  2002,   304,     4,     2,     2,     0],\n",
      "        [   73,   293,  8817,     4,     2,     0,     0,     0],\n",
      "        [ 2748,   103,     4,     2,     0,     0,     0,     0],\n",
      "        [    6,     9,     2,     0,     0,     0,     0,     0],\n",
      "        [ 1956,  3067,     0,     0,     0,     0,     0,     0],\n",
      "        [    6,     4,     0,     0,     0,     0,     0,     0],\n",
      "        [    2,     2,     0,     0,     0,     0,     0,     0]])\n",
      "mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 0],\n",
      "        [1, 1, 1, 1, 1, 0, 0, 0],\n",
      "        [1, 1, 1, 1, 0, 0, 0, 0],\n",
      "        [1, 1, 1, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0],\n",
      "        [1, 1, 0, 0, 0, 0, 0, 0]], dtype=torch.uint8)\n",
      "max_target_len: 10\n"
     ]
    }
   ],
   "source": [
    "small_batch_size = 8\n",
    "batches = batch2TrainingData(voc, [random.choice(pairs) for _ in range(small_batch_size)])\n",
    "input_variable, lengths, target_variable, mask, max_target_len = batches\n",
    "\n",
    "print(\"input_variable:\", input_variable)\n",
    "print(\"lengths:\", lengths)\n",
    "print(\"target_variable:\", target_variable)\n",
    "print(\"mask:\", mask)\n",
    "print(\"max_target_len:\", max_target_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "metadata": {},
   "outputs": [],
   "source": [
    "class EncoderRNN(nn.Module):\n",
    "    def __init__(self, hidden_size, embedding, n_layers = 1, dropout= 0):\n",
    "        super(EncoderRNN, self).__init__()\n",
    "        self.n_layers = n_layers\n",
    "        self.hidden_size = hidden_size\n",
    "        self.embedding = embedding\n",
    "        # GRU takes an input_size and hidden_size -- for us since input_size is an embeddng of size hidden_size,\n",
    "        # input_size and hidden_size are identical\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, \n",
    "                          dropout = (0 if n_layers == 1 else dropout), bidirectional = True)\n",
    "        \n",
    "    def forward(self, input_seq, input_lengths, hidden = None):\n",
    "        embedded = self.embedding(input_seq)\n",
    "        # Pack padded bactch of sequence for RNN module\n",
    "        packed = torch.nn.utils.rnn.pack_padded_sequence(embedded, input_lengths)\n",
    "        outputs, hidden = self.gru(packed, hidden)\n",
    "        outputs, _ = torch.nn.utils.rnn.pad_packed_sequence(outputs)\n",
    "        outputs = outputs[:, :, :self.hidden_size] + outputs[:, :, self.hidden_size:] # add bidirectional outputs. \n",
    "        return outputs, hidden"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Attn(torch.nn.Module):\n",
    "    def __init__(self, method, hidden_size):\n",
    "        super(Attn, self).__init__()\n",
    "        self.method = method\n",
    "        if self.method not in ['dot', 'general', 'concat']:\n",
    "            raise ValueError(self.method, \"is not an appropriate attention method.\")\n",
    "        self.hidden_size = hidden_size\n",
    "        if self.method == 'general':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size, hidden_size)\n",
    "        elif self.method == 'concat':\n",
    "            self.attn = torch.nn.Linear(self.hidden_size * 2, hidden_size)\n",
    "            self.v = torch.nn.Parameter(torch.FloatTensor(hidden_size))\n",
    "\n",
    "    def dot_score(self, hidden, encoder_output):\n",
    "        return torch.sum(hidden * encoder_output, dim=2)\n",
    "\n",
    "    def general_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(encoder_output)\n",
    "        return torch.sum(hidden * energy, dim=2)\n",
    "\n",
    "    def concat_score(self, hidden, encoder_output):\n",
    "        energy = self.attn(torch.cat((hidden.expand(encoder_output.size(0), -1, -1), encoder_output), 2)).tanh()\n",
    "        return torch.sum(self.v * energy, dim=2)\n",
    "\n",
    "    def forward(self, hidden, encoder_outputs):\n",
    "        # Calculate the attention weights (energies) based on the given method\n",
    "        if self.method == 'general':\n",
    "            attn_energies = self.general_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'concat':\n",
    "            attn_energies = self.concat_score(hidden, encoder_outputs)\n",
    "        elif self.method == 'dot':\n",
    "            attn_energies = self.dot_score(hidden, encoder_outputs)\n",
    "\n",
    "        # Transpose max_length and batch_size dimensions\n",
    "        attn_energies = attn_energies.t()\n",
    "\n",
    "        # Return the softmax normalized probability scores (with added dimension)\n",
    "        return F.softmax(attn_energies, dim=1).unsqueeze(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "class LuongAttnDecoderRNN(nn.Module):\n",
    "     def __init__(self, attn_model, embedding,  hidden_size, output_size, n_layers = 1, dropout= 0.1):\n",
    "        super(LuongAttnDecoderRNN, self).__init__()\n",
    "        \n",
    "        self.attn_model = attn_model\n",
    "        self.hidden_size = hidden_size\n",
    "        self.output_size = output_size\n",
    "        self.n_layers = n_layers\n",
    "        self.dropout = dropout\n",
    "        \n",
    "        self.embedding = embedding\n",
    "        self.embedding_dropout = nn.Dropout(dropout)\n",
    "        self.gru = nn.GRU(hidden_size, hidden_size, n_layers, dropout = (0 if n_layers == 1 else dropout))\n",
    "        self.concat = nn.Linear(hidden_size * 2, hidden_size)\n",
    "        self.out = nn.Linear(hidden_size, output_size)\n",
    "        \n",
    "        self.attn = Attn(attn_model, hidden_size)\n",
    "        \n",
    "     def forward(self, input_step, last_hidden, encoder_outputs):\n",
    "            \n",
    "        # this is done one wrod at a time until you hit EOS\n",
    "        embedded = self.embedding(input_step)\n",
    "        embedded = self.embedding_dropout(embedded)\n",
    "            \n",
    "        rnn_output, hidden = self.gru(embedded, last_hidden)\n",
    "        attn_weights = self.attn(rnn_output, encoder_outputs)\n",
    "        \n",
    "        context = attn_weights.bmm(encoder_outputs.transpose(0, 1)) #bmm does a batch matmul\n",
    "        \n",
    "        rnn_output = rnn_output.squeeze(0)\n",
    "        context = context.squeeze(1)\n",
    "        \n",
    "        \n",
    "        concat_input = torch.cat((rnn_output, context), 1)\n",
    "        concat_output = torch.tanh(self.concat(concat_input))\n",
    "            \n",
    "        output = self.out(concat_output)\n",
    "        output = F.softmax(output, dim = 1)\n",
    "            \n",
    "        return output, hidden # need the previous hidden state for new \n",
    "            "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Training\n",
    "    \n",
    "<h4> First step is to define the loss function -- this is where we need the binary matrix, as we want to compute the negative log likelihood only for the elements which have 1 in the binary matrix, not the paddings\n",
    "   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "metadata": {},
   "outputs": [],
   "source": [
    "def maskLoss(inp, target, mask):\n",
    "    nTotal = mask.sum()\n",
    "    crossEntropy = -torch.log(torch.gather(inp, 1, target.view(-1, 1)).squeeze(1))\n",
    "    loss = crossEntropy.masked_select(mask).mean()\n",
    "    return loss, nTotal.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer,\n",
    "         decoder_optimizer, batch_size, clip, max_length= MAX_LENGTH):\n",
    "    \n",
    "    encoder_optimizer.zero_grad()\n",
    "    decoder_optimizer.zero_grad()\n",
    "    \n",
    "    loss = 0\n",
    "    print_losses = []\n",
    "    n_totals = 0\n",
    "    \n",
    "    encoder_outputs, encoder_hidden = encoder(input_variable, lengths)\n",
    "    \n",
    "    decoder_input = torch.LongTensor([[SOS_token for _ in range(batch_size)]])\n",
    "    decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "    # Model uses teacher forcing. \n",
    "    for t in range(max_target_len):\n",
    "        decoder_output, decoder_hidden = decoder(decoder_input, decoder_hidden, \n",
    "                                                 encoder_outputs)\n",
    "        \n",
    "        # set decoder input to be target variable -- Teacher Forcing\n",
    "        decoder_input = target_variable[t].view(1, -1)\n",
    "        \n",
    "        mask_loss, nTotal = maskLoss(decoder_output, target_variable[t], mask[t])\n",
    "        loss += mask_loss\n",
    "        print_losses.append(mask_loss.item() * nTotal)\n",
    "        n_totals += nTotal\n",
    "    \n",
    "    loss.backward() #backprop\n",
    "    \n",
    "    # gradient clipping\n",
    "    _ = torch.nn.utils.clip_grad_norm_(encoder.parameters(), clip)\n",
    "    _ = torch.nn.utils.clip_grad_norm_(decoder.parameters(), clip)\n",
    "    \n",
    "    encoder_optimizer.step()\n",
    "    decoder_optimizer.step()\n",
    "    \n",
    "    return sum(print_losses)/n_totals"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Now iterate the training over many batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "def trainIters(model_name,voc, pairs, encoder, decoder,encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers,\n",
    "              decoder_n_layers, n_iteration, batch_size, print_every, clip):\n",
    "    \n",
    "    # Load batches for each iteration\n",
    "    training_batches = [batch2TrainingData(voc, [random.choice(pairs) for _ in range(batch_size)])\n",
    "                       for _ in range(n_iteration)]\n",
    "\n",
    "    # initialization\n",
    "    print(\"Initializing ...\")\n",
    "    start_iteration = 1\n",
    "    print_loss = 0\n",
    "    \n",
    "    # Training Loop\n",
    "    print(\"Training ...\")\n",
    "    for iteration in range(start_iteration, n_iteration+1):\n",
    "        training_batch = training_batches[iteration-1]\n",
    "        input_variable, lengths, target_variable, mask, max_target_len = training_batch\n",
    "\n",
    "        loss = train(input_variable, lengths, target_variable, mask, max_target_len, encoder, decoder, embedding, encoder_optimizer,\n",
    "         decoder_optimizer, batch_size, clip)\n",
    "        print_loss +=loss\n",
    "        \n",
    "        if iteration % print_every == 0:\n",
    "            print_loss_avg = print_loss/print_every\n",
    "            print(\"Iteration: {}; Percent Complete {:.1f}%; Average Loss {:.4f}\".format(iteration, iteration/n_iteration,\n",
    "                                                                                       print_loss_avg))\n",
    "            print_loss = 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Let's run the model and see how it does. \n",
    "    \n",
    "<h4> Note the production level code -- include a checkpoint saver in the \n",
    "     trainIters code.\n",
    "     Specify Model names and parameters. The code below should be put into a different *task.py* file\n",
    "     which loads in the model dependencies. \n",
    "     Use argparse to give the user flexibility in selecting what attention model he/she wants to use. \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Encoder and Decoder ...\n",
      "Models built and we're ready to go!!\n"
     ]
    }
   ],
   "source": [
    "model_name = 'chatbot_model'\n",
    "attn_model = 'dot' # user can select this using argparse\n",
    "hidden_size = 500\n",
    "encoder_n_layers = 2\n",
    "decoder_n_layers = 2\n",
    "dropout = 0.1\n",
    "batch_size = 64\n",
    "\n",
    "print(\"Building Encoder and Decoder ...\")\n",
    "embedding = nn.Embedding(voc.num_words, hidden_size)\n",
    "encoder = EncoderRNN(hidden_size, embedding, encoder_n_layers, dropout)\n",
    "decoder = LuongAttnDecoderRNN(attn_model, embedding, hidden_size, voc.num_words, decoder_n_layers, dropout)\n",
    "print(\"Models built and we're ready to go!!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building Optimizers ...\n",
      "Starting Training...\n",
      "Initializing ...\n",
      "Training ...\n",
      "Iteraton: 100; Percent Complete 0.0%; Average Loss 4.8209\n",
      "Iteraton: 200; Percent Complete 0.1%; Average Loss 3.6346\n",
      "Iteraton: 300; Percent Complete 0.1%; Average Loss 2.6633\n",
      "Iteraton: 400; Percent Complete 0.1%; Average Loss 2.0513\n",
      "Iteraton: 500; Percent Complete 0.1%; Average Loss 1.6463\n",
      "Iteraton: 600; Percent Complete 0.1%; Average Loss 1.3975\n",
      "Iteraton: 700; Percent Complete 0.2%; Average Loss 1.2084\n",
      "Iteraton: 800; Percent Complete 0.2%; Average Loss 1.0035\n",
      "Iteraton: 900; Percent Complete 0.2%; Average Loss 0.8814\n",
      "Iteraton: 1000; Percent Complete 0.2%; Average Loss 0.7647\n",
      "Iteraton: 1100; Percent Complete 0.3%; Average Loss 0.6423\n",
      "Iteraton: 1200; Percent Complete 0.3%; Average Loss 0.5823\n",
      "Iteraton: 1300; Percent Complete 0.3%; Average Loss 0.5063\n",
      "Iteraton: 1400; Percent Complete 0.3%; Average Loss 0.4748\n",
      "Iteraton: 1500; Percent Complete 0.4%; Average Loss 0.4252\n",
      "Iteraton: 1600; Percent Complete 0.4%; Average Loss 0.4142\n",
      "Iteraton: 1700; Percent Complete 0.4%; Average Loss 0.3429\n",
      "Iteraton: 1800; Percent Complete 0.5%; Average Loss 0.3118\n",
      "Iteraton: 1900; Percent Complete 0.5%; Average Loss 0.3029\n",
      "Iteraton: 2000; Percent Complete 0.5%; Average Loss 0.2641\n",
      "Iteraton: 2100; Percent Complete 0.5%; Average Loss 0.2574\n",
      "Iteraton: 2200; Percent Complete 0.6%; Average Loss 0.2428\n",
      "Iteraton: 2300; Percent Complete 0.6%; Average Loss 0.2327\n",
      "Iteraton: 2400; Percent Complete 0.6%; Average Loss 0.1925\n",
      "Iteraton: 2500; Percent Complete 0.6%; Average Loss 0.1801\n",
      "Iteraton: 2600; Percent Complete 0.7%; Average Loss 0.1733\n",
      "Iteraton: 2700; Percent Complete 0.7%; Average Loss 0.1643\n",
      "Iteraton: 2800; Percent Complete 0.7%; Average Loss 0.1453\n",
      "Iteraton: 2900; Percent Complete 0.7%; Average Loss 0.1306\n",
      "Iteraton: 3000; Percent Complete 0.8%; Average Loss 0.1329\n",
      "Iteraton: 3100; Percent Complete 0.8%; Average Loss 0.1299\n",
      "Iteraton: 3200; Percent Complete 0.8%; Average Loss 0.1325\n",
      "Iteraton: 3300; Percent Complete 0.8%; Average Loss 0.1101\n",
      "Iteraton: 3400; Percent Complete 0.8%; Average Loss 0.0983\n",
      "Iteraton: 3500; Percent Complete 0.9%; Average Loss 0.0864\n",
      "Iteraton: 3600; Percent Complete 0.9%; Average Loss 0.0778\n",
      "Iteraton: 3700; Percent Complete 0.9%; Average Loss 0.0837\n",
      "Iteraton: 3800; Percent Complete 0.9%; Average Loss 0.0791\n",
      "Iteraton: 3900; Percent Complete 1.0%; Average Loss 0.0781\n",
      "Iteraton: 4000; Percent Complete 1.0%; Average Loss 0.0635\n"
     ]
    }
   ],
   "source": [
    "clip = 50.0\n",
    "learning_rate = 0.0001\n",
    "decoder_learning_ratio = 5.0 # decoder learns with a faster learning rate than encoder\n",
    "n_iteration = 4000\n",
    "print_every = 100\n",
    "#save_every  = 500\n",
    "\n",
    "encoder.train()\n",
    "decoder.train()\n",
    "\n",
    "print(\"Building Optimizers ...\")\n",
    "encoder_optimizer = optim.Adam(encoder.parameters(), lr = learning_rate)\n",
    "decoder_optimizer = optim.Adam(decoder.parameters(), lr = learning_rate * decoder_learning_ratio)\n",
    "\n",
    "print(\"Starting Training...\")\n",
    "trainIters(model_name,voc, pairs, encoder, decoder,encoder_optimizer, decoder_optimizer, embedding, encoder_n_layers,\n",
    "              decoder_n_layers, n_iteration, batch_size, print_every, clip)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3> Decode and Evaluate\n",
    "    \n",
    "<h4> Having trained a chatbot, we want to interact with it. To do so, we need to forward the input through the encoder model, prep encoder final state to be decoder hidden input. Now we don't use teacher forcing and just do a greedy search where the most likely word through a softmax get picked as the next input for the decoder. Return the collection of word tokens and scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GreedySearchDecoder(nn.modulesodule):\n",
    "    def __init__(self, encoder, decoder):\n",
    "        super(GreedySearchDecoder, self).__init__()\n",
    "        self.encoder = encoder\n",
    "        self.decoder = decoder\n",
    "        \n",
    "    def forward(self, input_seq, input_length, max_length):\n",
    "        encoder_outputs, encoder_hidden = self.encoder(input_seq, input_length)\n",
    "        decoder_hidden = encoder_hidden[:decoder.n_layers]\n",
    "        decoder_input = torch.ones(1, 1, dytpe = torch.long) * SOS_token\n",
    "        all_tokens = torch.zeros([0], dtype = torch.long)\n",
    "        all_scores = torch.zeros([0], dype = torch.long)\n",
    "        \n",
    "        for _ in range(max_length):\n",
    "            decoder_output, decoder_hidden = self.decoder(decoder_input, decoder_hidden, encoder_outputs)\n",
    "            print(decoder_output.shape)\n",
    "            decoder_scores, decoder_input = torch.max(decoder_output, dim= 1)\n",
    "            print(decoder_scores)\n",
    "            print(decoder_input)\n",
    "            \n",
    "            all_tokens = torch.cat((all_tokens, decoder_input),  dim = 0)\n",
    "            print(all_tokens)\n",
    "            all_scores = torch.cat((all_scores, decoder_scores), dim = 0)\n",
    "            decoder_input = torch.unsqueeze(decoder_input, 0)\n",
    "        return all_tokens, all_scores"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(encoder, decoder, searcher, voc, sentence, max_length = MAX_LENGTH):\n",
    "    indexes_batch = [indexes]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
